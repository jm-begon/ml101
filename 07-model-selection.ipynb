{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```\n",
    "___  ___          _      _            _           _   _\n",
    "|  \\/  |         | |    | |          | |         | | (_)\n",
    "| .  . | ___   __| | ___| |  ___  ___| | ___  ___| |_ _  ___  _ __\n",
    "| |\\/| |/ _ \\ / _` |/ _ \\ | / __|/ _ \\ |/ _ \\/ __| __| |/ _ \\| '_ \\\n",
    "| |  | | (_) | (_| |  __/ | \\__ \\  __/ |  __/ (__| |_| | (_) | | | |\n",
    "\\_|  |_/\\___/ \\__,_|\\___|_| |___/\\___|_|\\___|\\___|\\__|_|\\___/|_| |_|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Motivations\n",
    "In many circumstances, it is necessary to select a model. This might be a way\n",
    "to decide between models coming from very different classes or choose the best\n",
    "hyper-parameters (notably those controlling regularization--thus controlling\n",
    "the complexity).\n",
    "\n",
    "# Train/validation/test split\n",
    "The simplest approach consists in building upon the train/test split method.\n",
    "The original set is divided into three sets:\n",
    "- the training set, which is used to learn the model;\n",
    "- the validation set, which is used to select the model;\n",
    "- the test set, which is used to assess the final model once retained on the\n",
    "training+validation set.\n",
    "\n",
    "> TODO illustration\n",
    "\n",
    "> ###### Technical note\n",
    "> The more decisions are made based on the validation, the more it is crucial\n",
    "> to assess the final performance on an unbiased sets, as a very similar\n",
    "> situation to overfitting arise.\n",
    "\n",
    "\n",
    "> TODO example based on train_test_split\n",
    "\n",
    "\n",
    "Note that a validation set is also handy to monitor the evolution of errors\n",
    "with iterative learning algorithms.\n",
    "\n",
    "\n",
    "# Cross-validation-based model selection\n",
    "Cross-validation and splitting methods can be mixed. For instance, we can\n",
    "replace the validation set by a cross-validation round and keep a single test\n",
    "set.\n",
    "\n",
    "> TODO illustrations + example\n",
    "\n",
    "It is also possible to do a nested cross-validation.\n",
    "\n",
    "> ###### Recommendation\n",
    "> When the purpose of doing model selection is finding the best\n",
    "> hyper-parameters, the CV+test set approach is the most sensible.\n",
    "> Indeed the CV part will assess how the hyper-parameters perform on average,\n",
    "> which is more stable than relying on a sole validation set. It is however\n",
    "> much more costly."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}