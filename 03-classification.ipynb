{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```\n",
    " _____ _               _  __ _           _   _\n",
    "/  __ \\ |             (_)/ _(_)         | | (_)\n",
    "| /  \\/ | __ _ ___ ___ _| |_ _  ___ __ _| |_ _  ___  _ __\n",
    "| |   | |/ _` / __/ __| |  _| |/ __/ _` | __| |/ _ \\| '_ \\\n",
    "| \\__/\\ | (_| \\__ \\__ \\ | | | | (_| (_| | |_| | (_) | | | |\n",
    " \\____/_|\\__,_|___/___/_|_| |_|\\___\\__,_|\\__|_|\\___/|_| |_|\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "from helper import get_cls_X_y, plt_decorate, Color, plot_boundary, get_orange_blue_cmap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A 2D binary classification problem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X, y = get_cls_X_y()\n",
    "\n",
    "\n",
    "def plot_dataset(X, y, title=None):\n",
    "    sel = y == 0\n",
    "    plt.scatter(X[sel, 0], X[sel, 1], color=Color.ORANGE.value, marker=(5, 1),\n",
    "                edgecolors=\"k\")\n",
    "\n",
    "    sel = y == 1\n",
    "    plt.scatter(X[sel, 0], X[sel, 1], color=Color.BLUE.value, marker=\"o\",\n",
    "                edgecolors=\"k\")\n",
    "\n",
    "    plt_decorate(title=title, xlabel=\"$x_0$\", ylabel=\"$x_1$\")\n",
    "\n",
    "plot_dataset(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision trees\n",
    "[Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "is a common building block for more evolved methods. It is a hierarchical\n",
    "structure (a binary tree in CS terms) composed of internal (or splitting) nodes\n",
    "and leaves (or external nodes). A prediction is made by propagating a sample from\n",
    "the root. At each internal node, the sample can only go down one branch. A\n",
    "prediction is associated to each leaf."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=3).fit(X, y)  # Train the decision tree\n",
    "mcr = zero_one_loss(y, model.predict(X))  # Compute the error\n",
    "print(\"Misclassification rate: {:.1f} %\".format(mcr*100))\n",
    "plot_boundary(model, X, y, cmap = get_orange_blue_cmap())  # plot the decision bounday\n",
    "plot_dataset(X, y, title=\"Decision boundary\")  # plot the dataset on top"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = tree.plot_tree(\n",
    "    model,\n",
    "    feature_names=[\"$x_0$\", \"$x_1$\"],\n",
    "    filled=True,\n",
    "    label=\"none\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ###### Technical note\n",
    "> At a high level, the learning algorithm (responsible to come up with the\n",
    "> decision tree) will recursively split (ie. partition in\n",
    "> two subsets) the dataset on some of its input feature.\n",
    "\n",
    "\n",
    "## Tree depth\n",
    "The number of decisions along the longest branch is called the depth of tree.\n",
    "It is an important parameter (although it usually makes more sense to control\n",
    "it indirectly). You can play on the example above to see how the boundary is\n",
    "affected\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-class classification\n",
    "There are several ways to handle more than two classes. Some algorithms (like\n",
    "decision trees, neural networks) naturally support multi-class classification.\n",
    "When this is not the case, there are a couple of strategies to handle more than\n",
    "two classes with binary classifiers (such as `one-versus-all` or\n",
    "`one-versus-rest` approaches).\n",
    "\n",
    "# Classification and regression\n",
    "# Regression trees\n",
    "Decision tree works also for regression. There are a few technical differences\n",
    "in the tree growing process, but the algorithm is the same at a high level.\n",
    "The leaf prediction in regression is given by taking the average output over\n",
    "the instances reaching that leaf.\n",
    "\n",
    "# Linear classifier\n",
    "## Binary case\n",
    "A binary linear classifier has the form\n",
    "$\\hat{y}(x) = \\text{sign} \\left( w^T x + b\\right)$,\n",
    "where $\\text{sign}$ is a predicate indicating whether its input is positive\n",
    "or not. This results in linear boundaries in the input space.\n",
    "\n",
    "Traditional linear classifiers include\n",
    "- [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html);\n",
    "- [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html);\n",
    "\n",
    "## Multi-class case\n",
    "Multi-class classification is usually handled through having one hyper-plane\n",
    "per class and comparing where an input falls with respect to each hyper-plane:\n",
    "> $$\\hat{y}(x) = \\arg\\max_{1 \\leq k \\leq K} w_k^T x + b_k$$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}